{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "b076da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "fafb172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_volume = nib.load(\"../datasets/3702_left_knee_mask_final.nii.gz\")\n",
    "ct_data = ct_volume.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "7918b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt, label\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "def watershed_segmentation(volume):\n",
    "    \"\"\"\n",
    "    Applies 3D watershed segmentation to a binary volume using distance transform and local maxima.\n",
    "\n",
    "    Parameters:\n",
    "    - volume (np.ndarray): A 3D binary mask volume.\n",
    "\n",
    "    Returns:\n",
    "    - labels (np.ndarray): A 3D array of watershed-labeled regions.\n",
    "    \"\"\"\n",
    "    # Ensure input is boolean\n",
    "    binary_volume = volume.astype(bool)\n",
    "    \n",
    "    # Compute the Euclidean distance transform\n",
    "    distance = distance_transform_edt(binary_volume)\n",
    "    \n",
    "    # Detect local maxima to serve as markers\n",
    "    coordinates = peak_local_max(\n",
    "        distance,\n",
    "        footprint=np.ones((100, 100, 100)),\n",
    "        labels=binary_volume,\n",
    "        exclude_border=False\n",
    "    )\n",
    "    \n",
    "    # Create marker image\n",
    "    marker_mask = np.zeros(distance.shape, dtype=bool)\n",
    "    marker_mask[tuple(coordinates.T)] = True\n",
    "    \n",
    "    # Label the markers\n",
    "    markers, _ = label(marker_mask)\n",
    "    \n",
    "    # Apply the watershed algorithm\n",
    "    labels = watershed(-distance, markers, mask=binary_volume)\n",
    "    \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "9af46a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_3d = np.stack(ct_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "669099f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = watershed_segmentation(volume_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25de52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mayavi.mlab as mlab\n",
    "\n",
    "mlab.contour3d(volume_3d, color=(1,1,1))\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_rgb = np.zeros((512, 512, 216, 3), dtype=np.uint8)\n",
    "\n",
    "volume_rgb[labels == 0] = [128, 128, 128]\n",
    "volume_rgb[labels == 1] = [0, 255, 0]\n",
    "volume_rgb[labels == 2] = [255, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlab.contour3d((labels == 1).astype(np.uint8), color=(0, 1, 0), opacity=0.5)\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "390f039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_rgb = volume_rgb.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "8f9cf60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tensor_3d = torch.from_numpy(volume_rgb).permute(3, 2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "0d626daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 216, 512, 512])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "999a60ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rgb_slice = tensor_3d[:, 110, :, :]\n",
    "rgb_slice_np = rgb_slice.permute(1, 2, 0).numpy()\n",
    "plt.imshow(rgb_slice_np)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4763f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\inside-cnn\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\inside-cnn\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "model_2d = models.densenet121(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "015cb3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2d.classifier = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2821346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_conv2d(conv2d):\n",
    "\n",
    "    in_channels = conv2d.in_channels\n",
    "    out_channels = conv2d.out_channels\n",
    "\n",
    "    k = conv2d.kernel_size[0]\n",
    "    kernel_size_3d = (k, k, k)\n",
    "\n",
    "    s = conv2d.stride[0]\n",
    "    stride_3d = (s, s, s)\n",
    "    \n",
    "    if hasattr(conv2d, \"padding\") and isinstance(conv2d.padding, tuple):\n",
    "        p = conv2d.padding[0]\n",
    "        padding_3d = (p, p, p)\n",
    "    else:\n",
    "        padding_3d = 0\n",
    "\n",
    "    conv3d = nn.Conv3d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=kernel_size_3d,\n",
    "        stride=stride_3d,\n",
    "        padding=padding_3d,\n",
    "        bias=conv2d.bias\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        weight_2d = conv2d.weight.data\n",
    "        weight_3d = weight_2d.unsqueeze(2).repeat(1, 1, k, 1, 1)/k\n",
    "        conv3d.weight.data.copy_(weight_3d)\n",
    "        if conv2d.bias is not None:\n",
    "            conv3d.bias.data.copy_(conv2d.bias.data)\n",
    "    return conv3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bda4c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv0 = nn.Conv2d(3, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False)\n",
    "conv3d = inflate_conv2d(conv0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2911d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_batchnorm2d(bn2d):\n",
    "    bn3d = nn.BatchNorm3d(\n",
    "        bn2d.num_features,\n",
    "        eps=bn2d.eps,\n",
    "        momentum=bn2d.momentum,\n",
    "        affine=bn2d.affine,\n",
    "        track_running_stats=bn2d.track_running_stats\n",
    "    )\n",
    "\n",
    "    if bn2d.affine:\n",
    "        with torch.no_grad():\n",
    "            bn3d.weight.data.copy_(bn2d.weight.data)\n",
    "            bn3d.bias.data.copy_(bn2d.bias.data)\n",
    "    \n",
    "    if bn2d.track_running_stats:\n",
    "        bn3d.running_mean.data.copy_(bn2d.running_mean.data)\n",
    "        bn3d.running_var.copy_(bn2d.running_var.data)\n",
    "\n",
    "    return bn3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5628106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm0 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "norm3d = inflate_batchnorm2d(norm0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d27338ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_maxpool2d(maxpool2d):\n",
    "\n",
    "    maxpool3d = nn.MaxPool3d(\n",
    "        kernel_size=maxpool2d.kernel_size,\n",
    "        stride=maxpool2d.stride,\n",
    "        padding=maxpool2d.padding,\n",
    "        dilation=maxpool2d.dilation,\n",
    "        ceil_mode=maxpool2d.ceil_mode\n",
    "    )\n",
    "\n",
    "    return maxpool3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "63099a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool0 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "inflate_maxpool2d(pool0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2459a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_avgpool2d(avgpool2d):\n",
    "        \n",
    "    avgpool3d = nn.AvgPool3d(\n",
    "        kernel_size=avgpool2d.kernel_size,\n",
    "        stride=avgpool2d.stride,\n",
    "        padding=avgpool2d.padding\n",
    "    )\n",
    "\n",
    "    return avgpool3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd92d507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AvgPool3d(kernel_size=2, stride=2, padding=0)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "inflate_avgpool2d(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ecf550be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_densenet121(model_2d):\n",
    "    for name, module in model_2d.named_children():\n",
    "        # Recursively go inside children\n",
    "        convert_densenet121(module)\n",
    "\n",
    "        # Convert Conv2d → Conv3d\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            new_layer = inflate_conv2d(module)\n",
    "            setattr(model_2d, name, new_layer)\n",
    "\n",
    "        # Convert BatchNorm2d → BatchNorm3d\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            new_layer = inflate_batchnorm2d(module)\n",
    "            setattr(model_2d, name, new_layer)\n",
    "\n",
    "        # Convert MaxPool2d → MaxPool3d\n",
    "        elif isinstance(module, nn.MaxPool2d):\n",
    "            new_layer = inflate_maxpool2d(module)\n",
    "            setattr(model_2d, name, new_layer)\n",
    "\n",
    "        # Convert AvgPool2d → AvgPool3d\n",
    "        elif isinstance(module, nn.AvgPool2d):\n",
    "            new_layer = inflate_avgpool2d(module)\n",
    "            setattr(model_2d, name, new_layer)\n",
    "\n",
    "    return model_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "63eca0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d = convert_densenet121(model_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c78aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_3d = tensor_3d.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "064c9230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 216, 512, 512])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "22afe184",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model_3d(tensor_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c12c2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.conv0 Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
      "features.denseblock1.denselayer1.conv1 Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer1.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer2.conv1 Conv3d(96, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer2.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer3.conv1 Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer3.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer4.conv1 Conv3d(160, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer4.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer5.conv1 Conv3d(192, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer5.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer6.conv1 Conv3d(224, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer6.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.transition1.conv Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer1.conv1 Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer1.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer2.conv1 Conv3d(160, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer2.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer3.conv1 Conv3d(192, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer3.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer4.conv1 Conv3d(224, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer4.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer5.conv1 Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer5.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer6.conv1 Conv3d(288, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer6.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer7.conv1 Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer7.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer8.conv1 Conv3d(352, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer8.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer9.conv1 Conv3d(384, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer9.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer10.conv1 Conv3d(416, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer10.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer11.conv1 Conv3d(448, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer11.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer12.conv1 Conv3d(480, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer12.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.transition2.conv Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer1.conv1 Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer1.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer2.conv1 Conv3d(288, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer2.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer3.conv1 Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer3.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer4.conv1 Conv3d(352, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer4.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer5.conv1 Conv3d(384, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer5.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer6.conv1 Conv3d(416, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer6.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer7.conv1 Conv3d(448, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer7.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer8.conv1 Conv3d(480, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer8.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer9.conv1 Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer9.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer10.conv1 Conv3d(544, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer10.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer11.conv1 Conv3d(576, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer11.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer12.conv1 Conv3d(608, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer12.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer13.conv1 Conv3d(640, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer13.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer14.conv1 Conv3d(672, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer14.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer15.conv1 Conv3d(704, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer15.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer16.conv1 Conv3d(736, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer16.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer17.conv1 Conv3d(768, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer17.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer18.conv1 Conv3d(800, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer18.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer19.conv1 Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer19.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer20.conv1 Conv3d(864, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer20.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer21.conv1 Conv3d(896, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer21.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer22.conv1 Conv3d(928, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer22.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer23.conv1 Conv3d(960, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer23.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer24.conv1 Conv3d(992, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer24.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.transition3.conv Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer1.conv1 Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer1.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer2.conv1 Conv3d(544, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer2.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer3.conv1 Conv3d(576, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer3.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer4.conv1 Conv3d(608, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer4.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer5.conv1 Conv3d(640, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer5.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer6.conv1 Conv3d(672, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer6.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer7.conv1 Conv3d(704, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer7.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer8.conv1 Conv3d(736, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer8.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer9.conv1 Conv3d(768, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer9.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer10.conv1 Conv3d(800, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer10.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer11.conv1 Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer11.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer12.conv1 Conv3d(864, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer12.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer13.conv1 Conv3d(896, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer13.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer14.conv1 Conv3d(928, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer14.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer15.conv1 Conv3d(960, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer15.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer16.conv1 Conv3d(992, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer16.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "for name, module in model_3d.named_modules():\n",
    "    if isinstance(module, nn.Conv3d):\n",
    "        print(name, module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f85764e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = {}\n",
    "\n",
    "def get_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        feature_maps[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a0e953c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x163a7a28d40>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3d.features.denseblock4.denselayer16.conv2.register_forward_hook(get_hook(\"last-convolution-layer\"))\n",
    "model_3d.features.denseblock4.denselayer15.conv2.register_forward_hook(get_hook(\"third-last-convolution-layer\"))\n",
    "model_3d.features.denseblock4.denselayer14.conv2.register_forward_hook(get_hook(\"fifth-last-convolution-layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46c322b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d.eval()\n",
    "with torch.no_grad():\n",
    "    _ = model_3d(tensor_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "696551b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 6, 16, 16])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps[\"fifth-last-convolution-layer\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "902183b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 6, 16, 16])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps[\"last-convolution-layer\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "13a1dfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "gap = F.adaptive_avg_pool3d(feature_maps[\"last-convolution-layer\"], output_size=1)\n",
    "gap = gap.view(gap.size(0), -1)\n",
    "gap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0182b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = F.cosine_similarity(f1, f2, dim=1)\n",
    "print(f\"Cosine similarity: {cos_sim.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
