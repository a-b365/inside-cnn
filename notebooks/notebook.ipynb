{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b076da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import regionprops\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.morphology import remove_small_objects, binary_opening, disk\n",
    "from scipy.ndimage import binary_fill_holes, zoom, distance_transform_edt, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a0761b",
   "metadata": {},
   "source": [
    "# Semi Automated Mask Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99342e1",
   "metadata": {},
   "source": [
    "#### Follow these steps\n",
    "- ##### 1. For each slice x such that 0 <= x < 90, threshold(240) and min_size(800)\n",
    "- ##### 2. For each slice x such that 90 <= x < 94, remove blobs(top 1 feature), threshold(160) and min_size(800)\n",
    "- ##### 3. For each slice x such that 94 <= x < 102, threshold(180) and min_size(800)\n",
    "- ##### 4. For slice x such that x == 103, threshold(280) and min_size(800)\n",
    "- ##### 5. For each slice x such that 104 <= x < 108, threshold(130) and min_size(60)\n",
    "- ##### 6. For each slice x such that 108 <= x < 130, threshold(180) and min_size(1200)\n",
    "- ##### 7. For each slice x such that x >= 130, threshold(240) and min_size(800)\n",
    "\n",
    "##### Note: For background mask generation, use threshold(-100) and min_size(800) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e61ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation\n",
    "volume = nib.load(\"../datasets/3702_left_knee.nii.gz\")\n",
    "data = volume.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0b2e4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mask = np.zeros_like(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5266a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_slice(i, threshold_value=240, min_size=800, zoom_factor=4, sigma=2):\n",
    "    \"\"\"\n",
    "    Create a binary mask for a specific slice index in the CT volume.\n",
    "\n",
    "    Parameters:\n",
    "        i (int): Slice index to process.\n",
    "        threshold_value (int): Intensity threshold for binarization.\n",
    "        sigma (float): Gaussian blur sigma value.\n",
    "        zoom_factor (int or float): Factor to zoom in before processing.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A binary mask for the given slice.\n",
    "    \"\"\"\n",
    "    # Extract the slice\n",
    "    slice = data[:, :, i]\n",
    "\n",
    "    # Upsample to improve resolution for thresholding\n",
    "    zoom_in = zoom(slice, (zoom_factor, zoom_factor), order=0)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = gaussian(zoom_in, sigma=sigma)\n",
    "\n",
    "    # Thresholding to create binary mask\n",
    "    _, thresh = cv2.threshold(blurred, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Downsample to original shape\n",
    "    zoom_out = zoom(thresh, (1/zoom_factor, 1/zoom_factor), order=0)\n",
    "\n",
    "    # Fill internal holes\n",
    "    filled_mask = binary_fill_holes(zoom_out)\n",
    "\n",
    "    # Optional: Apply morphological opening to remove small artifacts\n",
    "    opening = binary_opening(filled_mask, disk(1), mode=\"ignore\")\n",
    "\n",
    "    # Remove small objects to clean up the mask\n",
    "    clean_mask = remove_small_objects(opening.astype(bool), min_size=min_size)\n",
    "\n",
    "    return clean_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7d07eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_blobs(clean_mask):\n",
    "\n",
    "    # Distance transform and peak detection\n",
    "    distance = distance_transform_edt(clean_mask)\n",
    "    coords = peak_local_max(distance, labels=clean_mask, footprint=np.ones((10, 10)), min_distance=25)\n",
    "    \n",
    "    # Label the peaks\n",
    "    markers = np.zeros_like(distance, dtype=bool)\n",
    "    markers[tuple(coords.T)] = True\n",
    "    markers, _ = label(markers)\n",
    "\n",
    "    # Watershed to separate loosely connected regions\n",
    "    labels_ws = watershed(-distance, markers, mask=clean_mask)\n",
    "\n",
    "    output_mask = np.zeros_like(clean_mask, dtype=bool)\n",
    "    for region in sorted(regionprops(labels_ws), key=lambda r: r.area, reverse=True)[:1]:\n",
    "        output_mask[labels_ws == region.label] = True\n",
    "\n",
    "    return output_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4b309621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of slices to process\n",
    "def process_slices(start, end, threshold_value, min_size):\n",
    "\n",
    "    for i in range(start, end):\n",
    "        \n",
    "        # Generate mask from the slice\n",
    "        clean_mask = mask_slice(i, threshold_value, min_size)\n",
    "\n",
    "        output_mask = remove_blobs(clean_mask)\n",
    "\n",
    "        # Store the mask in the binary volume\n",
    "        binary_mask[:, :, i] = output_mask.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c094ed0d",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fafb172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_volume = nib.load(\"../datasets/3702_left_knee_mask_final.nii.gz\")\n",
    "ct_data = ct_volume.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a7d30daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_volume = nib.load(\"../datasets/3702_left_knee_bg_mask.nii.gz\")\n",
    "bg_data = bg_volume.get_fdata().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7918b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt, label\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "def watershed_segmentation(volume):\n",
    "    \"\"\"\n",
    "    Applies 3D watershed segmentation to a binary volume using distance transform and local maxima.\n",
    "\n",
    "    Parameters:\n",
    "    - volume (np.ndarray): A 3D binary mask volume.\n",
    "\n",
    "    Returns:\n",
    "    - labels (np.ndarray): A 3D array of watershed-labeled regions.\n",
    "    \"\"\"\n",
    "    # Ensure input is boolean\n",
    "    binary_volume = volume.astype(bool)\n",
    "    \n",
    "    # Compute the Euclidean distance transform\n",
    "    distance = distance_transform_edt(binary_volume)\n",
    "    \n",
    "    # Detect local maxima to serve as markers\n",
    "    coordinates = peak_local_max(\n",
    "        distance,\n",
    "        footprint=np.ones((100, 100, 100)),\n",
    "        labels=binary_volume,\n",
    "        exclude_border=False\n",
    "    )\n",
    "    \n",
    "    # Create marker image\n",
    "    marker_mask = np.zeros(distance.shape, dtype=bool)\n",
    "    marker_mask[tuple(coordinates.T)] = True\n",
    "    \n",
    "    # Label the markers\n",
    "    markers, _ = label(marker_mask)\n",
    "    \n",
    "    # Apply the watershed algorithm\n",
    "    labels = watershed(-distance, markers, mask=binary_volume)\n",
    "    \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9af46a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_3d = np.stack(ct_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "669099f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = watershed_segmentation(volume_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c25de52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mayavi.mlab as mlab\n",
    "\n",
    "mlab.contour3d(volume_3d, color=(1,1,1))\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "421b86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_rgb = np.zeros((512, 512, 216, 3), dtype=np.uint8)\n",
    "\n",
    "volume_rgb[bg_data == 128] = [128, 128, 128]\n",
    "volume_rgb[labels == 1] = [0, 255, 0]\n",
    "volume_rgb[labels == 2] = [255, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "db50f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlab.contour3d((labels == 2).astype(np.uint8), color=(0, 1, 0), opacity=0.5)\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "390f039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_rgb = volume_rgb.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8f9cf60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tensor_3d = torch.from_numpy(volume_rgb).permute(3, 2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b9481b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.       , 0.5019608, 1.       ], dtype=float32)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(volume_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0d626daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 216, 512, 512])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "999a60ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rgb_slice = tensor_3d[:, 110, :, :]\n",
    "rgb_slice_np = rgb_slice.permute(1, 2, 0).numpy()\n",
    "plt.imshow(rgb_slice_np)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4763f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\inside-cnn\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\inside-cnn\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "model_2d = models.densenet121(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "015cb3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2d.classifier = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2821346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_conv2d(conv2d):\n",
    "\n",
    "    in_channels = conv2d.in_channels\n",
    "    out_channels = conv2d.out_channels\n",
    "\n",
    "    k = conv2d.kernel_size[0]\n",
    "    kernel_size_3d = (k, k, k)\n",
    "\n",
    "    s = conv2d.stride[0]\n",
    "    stride_3d = (s, s, s)\n",
    "    \n",
    "    if hasattr(conv2d, \"padding\") and isinstance(conv2d.padding, tuple):\n",
    "        p = conv2d.padding[0]\n",
    "        padding_3d = (p, p, p)\n",
    "    else:\n",
    "        padding_3d = 0\n",
    "\n",
    "    conv3d = nn.Conv3d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=kernel_size_3d,\n",
    "        stride=stride_3d,\n",
    "        padding=padding_3d,\n",
    "        bias=conv2d.bias\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        weight_2d = conv2d.weight.data\n",
    "        weight_3d = weight_2d.unsqueeze(2).repeat(1, 1, k, 1, 1)/k\n",
    "        conv3d.weight.data.copy_(weight_3d)\n",
    "        if conv2d.bias is not None:\n",
    "            conv3d.bias.data.copy_(conv2d.bias.data)\n",
    "    return conv3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "bda4c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv0 = nn.Conv2d(3, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False)\n",
    "conv3d = inflate_conv2d(conv0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2911d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_batchnorm2d(bn2d):\n",
    "    bn3d = nn.BatchNorm3d(\n",
    "        bn2d.num_features,\n",
    "        eps=bn2d.eps,\n",
    "        momentum=bn2d.momentum,\n",
    "        affine=bn2d.affine,\n",
    "        track_running_stats=bn2d.track_running_stats\n",
    "    )\n",
    "\n",
    "    if bn2d.affine:\n",
    "        with torch.no_grad():\n",
    "            bn3d.weight.data.copy_(bn2d.weight.data)\n",
    "            bn3d.bias.data.copy_(bn2d.bias.data)\n",
    "    \n",
    "    if bn2d.track_running_stats:\n",
    "        bn3d.running_mean.data.copy_(bn2d.running_mean.data)\n",
    "        bn3d.running_var.copy_(bn2d.running_var.data)\n",
    "\n",
    "    return bn3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5628106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm0 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "norm3d = inflate_batchnorm2d(norm0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d27338ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_maxpool2d(maxpool2d):\n",
    "\n",
    "    maxpool3d = nn.MaxPool3d(\n",
    "        kernel_size=maxpool2d.kernel_size,\n",
    "        stride=maxpool2d.stride,\n",
    "        padding=maxpool2d.padding,\n",
    "        dilation=maxpool2d.dilation,\n",
    "        ceil_mode=maxpool2d.ceil_mode\n",
    "    )\n",
    "\n",
    "    return maxpool3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "63099a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool0 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "inflate_maxpool2d(pool0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2459a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_avgpool2d(avgpool2d):\n",
    "        \n",
    "    avgpool3d = nn.AvgPool3d(\n",
    "        kernel_size=avgpool2d.kernel_size,\n",
    "        stride=avgpool2d.stride,\n",
    "        padding=avgpool2d.padding\n",
    "    )\n",
    "\n",
    "    return avgpool3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "cd92d507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AvgPool3d(kernel_size=2, stride=2, padding=0)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "inflate_avgpool2d(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ecf550be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_densenet121(model_2d):\n",
    "    for name, module in model_2d.named_children():\n",
    "        # Recursively go inside children\n",
    "        convert_densenet121(module)\n",
    "\n",
    "        # Convert Conv2d → Conv3d\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            new_layer = inflate_conv2d(module)\n",
    "            setattr(model_2d, name, new_layer)\n",
    "\n",
    "        # Convert BatchNorm2d → BatchNorm3d\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            new_layer = inflate_batchnorm2d(module)\n",
    "            setattr(model_2d, name, new_layer)\n",
    "\n",
    "        # Convert MaxPool2d → MaxPool3d\n",
    "        elif isinstance(module, nn.MaxPool2d):\n",
    "            new_layer = inflate_maxpool2d(module)\n",
    "            setattr(model_2d, name, new_layer)\n",
    "\n",
    "        # Convert AvgPool2d → AvgPool3d\n",
    "        elif isinstance(module, nn.AvgPool2d):\n",
    "            new_layer = inflate_avgpool2d(module)\n",
    "            setattr(model_2d, name, new_layer)\n",
    "\n",
    "    return model_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "63eca0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d = convert_densenet121(model_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "58c78aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_3d = tensor_3d.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "064c9230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 216, 512, 512])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "22afe184",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model_3d(tensor_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3c12c2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.conv0 Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
      "features.denseblock1.denselayer1.conv1 Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer1.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer2.conv1 Conv3d(96, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer2.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer3.conv1 Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer3.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer4.conv1 Conv3d(160, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer4.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer5.conv1 Conv3d(192, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer5.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer6.conv1 Conv3d(224, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock1.denselayer6.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.transition1.conv Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer1.conv1 Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer1.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer2.conv1 Conv3d(160, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer2.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer3.conv1 Conv3d(192, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer3.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer4.conv1 Conv3d(224, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer4.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer5.conv1 Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer5.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer6.conv1 Conv3d(288, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer6.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer7.conv1 Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer7.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer8.conv1 Conv3d(352, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer8.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer9.conv1 Conv3d(384, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer9.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer10.conv1 Conv3d(416, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer10.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer11.conv1 Conv3d(448, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer11.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer12.conv1 Conv3d(480, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock2.denselayer12.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.transition2.conv Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer1.conv1 Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer1.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer2.conv1 Conv3d(288, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer2.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer3.conv1 Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer3.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer4.conv1 Conv3d(352, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer4.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer5.conv1 Conv3d(384, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer5.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer6.conv1 Conv3d(416, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer6.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer7.conv1 Conv3d(448, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer7.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer8.conv1 Conv3d(480, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer8.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer9.conv1 Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer9.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer10.conv1 Conv3d(544, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer10.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer11.conv1 Conv3d(576, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer11.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer12.conv1 Conv3d(608, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer12.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer13.conv1 Conv3d(640, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer13.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer14.conv1 Conv3d(672, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer14.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer15.conv1 Conv3d(704, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer15.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer16.conv1 Conv3d(736, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer16.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer17.conv1 Conv3d(768, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer17.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer18.conv1 Conv3d(800, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer18.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer19.conv1 Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer19.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer20.conv1 Conv3d(864, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer20.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer21.conv1 Conv3d(896, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer21.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer22.conv1 Conv3d(928, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer22.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer23.conv1 Conv3d(960, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer23.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer24.conv1 Conv3d(992, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock3.denselayer24.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.transition3.conv Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer1.conv1 Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer1.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer2.conv1 Conv3d(544, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer2.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer3.conv1 Conv3d(576, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer3.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer4.conv1 Conv3d(608, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer4.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer5.conv1 Conv3d(640, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer5.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer6.conv1 Conv3d(672, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer6.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer7.conv1 Conv3d(704, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer7.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer8.conv1 Conv3d(736, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer8.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer9.conv1 Conv3d(768, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer9.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer10.conv1 Conv3d(800, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer10.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer11.conv1 Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer11.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer12.conv1 Conv3d(864, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer12.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer13.conv1 Conv3d(896, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer13.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer14.conv1 Conv3d(928, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer14.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer15.conv1 Conv3d(960, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer15.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer16.conv1 Conv3d(992, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "features.denseblock4.denselayer16.conv2 Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "for name, module in model_3d.named_modules():\n",
    "    if isinstance(module, nn.Conv3d):\n",
    "        print(name, module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f85764e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = {}\n",
    "\n",
    "def get_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        feature_maps[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0a0e953c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x162f57f31d0>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3d.features.denseblock4.denselayer16.conv2.register_forward_hook(get_hook(\"last-convolution-layer\"))\n",
    "model_3d.features.denseblock4.denselayer15.conv2.register_forward_hook(get_hook(\"third-last-convolution-layer\"))\n",
    "model_3d.features.denseblock4.denselayer14.conv2.register_forward_hook(get_hook(\"fifth-last-convolution-layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "46c322b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d.eval()\n",
    "with torch.no_grad():\n",
    "    _ = model_3d(tensor_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "696551b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 6, 16, 16])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps[\"fifth-last-convolution-layer\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "902183b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 6, 16, 16])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps[\"last-convolution-layer\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "13a1dfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "gap = F.adaptive_avg_pool3d(feature_maps[\"last-convolution-layer\"], output_size=1)\n",
    "gap = gap.view(gap.size(0), -1)\n",
    "gap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0182b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = F.cosine_similarity(f1, f2, dim=1)\n",
    "print(f\"Cosine similarity: {cos_sim.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af23e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
